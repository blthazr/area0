---
nameOverride: &app kube-prometheus-stack
alertmanager:
  alertmanagerSpec:
    podAntiAffinity: hard
    replicas: 2
    storage:
      volumeClaimTemplate:
        spec:
          resources:
            requests:
              storage: 1Gi
          storageClassName: ceph-block
  config:
    global:
      resolve_timeout: 5m
      slack_api_url: "${SECRET_ALERT_MANAGER_DISCORD_WEBHOOK}"
    inhibit_rules:
      - equal: ["alertname", "namespace"]
        source_matchers:
          - severity = "critical"
        target_matchers:
          - severity = "warning"
    receivers:
      - name: "null"
      - name: "discord"
        slack_configs:
          - channel: "#prometheus-alerts"
            icon_url: https://avatars3.githubusercontent.com/u/3380462
            send_resolved: true
            text: >-
              {{ range .Alerts -}}
                **Alert:** {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}

              **Description:** {{ if ne .Annotations.description ""}}{{ .Annotations.description }}{{else}}N/A{{ end }}

              **Details:**
                {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
                {{ end }}
              {{ end }}
            title: |-
              [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ if ne .CommonAnnotations.summary ""}}{{ .CommonAnnotations.summary }}{{ else }}{{ .CommonLabels.alertname }}{{ end }}
            username: "Prometheus"
    route:
      group_by: ["alertname", "job"]
      group_interval: 5m
      group_wait: 30s
      receiver: "discord"
      repeat_interval: 6h
      routes:
        - receiver: "null"
          matchers:
            - alertname =~ "InfoInhibitor|Watchdog"
        - receiver: "discord"
          continue: true
          matchers:
            - severity = "critical"
  ingress:
    enabled: true
    hosts:
      - &host "alert-manager.${SECRET_DOMAIN}"
    ingressClassName: nginx
    pathType: Prefix
    tls:
      - hosts:
          - *host
  resources:
    limits:
      memory: 100M
    requests:
      cpu: 10m
      memory: 50M
grafana:
  enabled: false
  forceDeployDashboards: true
  sidecar:
    dashboards:
      multicluster:
        etcd:
          enabled: true
kubeApiServer:
  enabled: true
kubeControllerManager:
  enabled: false # true
  endpoints:
    - "${K3S_NODE_1_ADDRESS}"
    - "${K3S_NODE_2_ADDRESS}"
    - "${K3S_NODE_3_ADDRESS}"
kubeEtcd:
  enabled: true
  endpoints:
    - "${K3S_NODE_1_ADDRESS}"
    - "${K3S_NODE_2_ADDRESS}"
    - "${K3S_NODE_3_ADDRESS}"
kubeProxy:
  enabled: false # true
  endpoints:
    - "${K3S_NODE_1_ADDRESS}"
    - "${K3S_NODE_2_ADDRESS}"
    - "${K3S_NODE_3_ADDRESS}"
kubeScheduler:
  enabled: false # true
  endpoints:
    - "${K3S_NODE_1_ADDRESS}"
    - "${K3S_NODE_2_ADDRESS}"
    - "${K3S_NODE_3_ADDRESS}"
kubelet:
  enabled: true
  serviceMonitor:
    metricRelabelings:
      - action: replace
        sourceLabels:
          - node
        targetLabel: instance
kube-state-metrics:
  metricLabelsAllowlist:
    - "persistentvolumeclaims=[*]"
  prometheus:
    monitor:
      enabled: true
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node
prometheus:
  ingress:
    enabled: true
    hosts:
      - &host "prometheus.${SECRET_DOMAIN}"
    ingressClassName: nginx
    pathType: Prefix
    tls:
      - hosts:
          - *host
  prometheusSpec:
    additionalScrapeConfigs:
      - job_name: minio
        honor_timestamps: true
        metrics_path: /minio/v2/metrics/cluster
        scheme: http
        scrape_interval: 1m
        scrape_timeout: 10s
        static_configs:
          - targets:
              - "${MINIO_ADDRESS}:9000"
      - job_name: node-exporter
        honor_timestamps: true
        scrape_interval: 1m
        scrape_timeout: 10s
        static_configs:
          - targets:
              - "${NAS_ADDRESS}:9100"
              - "${HOME_ASSISTANT_ADDRESS}:9100"
    enableAdminAPI: true
    podAnnotations:
      secret.reloader.stakater.com/reload: thanos-objstore-secret
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false
    replicas: 2
    replicaExternalLabelName: __replica__
    retention: 7d
    retentionSize: 8GB
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    storageSpec:
      volumeClaimTemplate:
        spec:
          resources:
            requests:
              storage: 10Gi
          storageClassName: ceph-block
    thanos:
      image: quay.io/thanos/thanos:v0.28.1
      objectStorageConfig:
        key: objstore.yml
        name: thanos-objstore-secret
      # renovate: datasource=docker depName=quay.io/thanos/thanos
      version: v0.28.1
    walCompression: true
  thanosService:
    enabled: true
  thanosServiceMonitor:
    enabled: true
